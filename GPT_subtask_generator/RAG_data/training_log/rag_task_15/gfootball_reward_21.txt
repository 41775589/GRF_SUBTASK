[DEBUG 11:58:13] git.cmd Popen(['git', 'version'], cwd=/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-0211/GPT_subtask_generator, stdin=None, shell=False, universal_newlines=False)
[DEBUG 11:58:13] git.cmd Popen(['git', 'version'], cwd=/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-0211/GPT_subtask_generator, stdin=None, shell=False, universal_newlines=False)
[INFO 11:58:13] root Saving to FileStorageObserver in results/sacred.
[DEBUG 11:58:14] pymarl Using capture mode "fd"
[INFO 11:58:14] pymarl Running command 'my_main'
[INFO 11:58:14] pymarl Started run with ID "1"
[DEBUG 11:58:14] pymarl Starting Heartbeat
[DEBUG 11:58:14] my_main Started
AAAAAAAAAA namespace(runner='parallel', mac='basic_mac', env='gfootball', common_reward=True, reward_scalarisation='sum', env_args={'map_name': '5_vs_5', 'num_agents': 2, 'representation': 'simple115', 'rewards': 'scoring, reward_21', 'time_limit': 150, 'seed': 560432508}, batch_size_run=10, test_nepisode=30, test_interval=10000, test_greedy=True, log_interval=10000, runner_log_interval=10000, learner_log_interval=10000, t_max=500000, use_cuda=True, buffer_cpu_only=True, use_tensorboard=True, use_wandb=False, wandb_team=None, wandb_project=None, wandb_mode='offline', wandb_save_model=False, save_model=False, save_model_interval=50000, checkpoint_path='', evaluate=False, render=False, load_step=0, save_replay=False, local_results_path='results', gamma=0.99, batch_size=10, buffer_size=10, lr=0.0003, optim_alpha=0.99, optim_eps=1e-05, grad_norm_clip=10, add_value_last_step=True, agent='rnn', hidden_dim=128, obs_agent_id=True, obs_last_action=False, repeat_id=1, label='default_label', hypergroup=None, action_selector='soft_policies', agent_output_type='pi_logits', critic_type='cv_critic', decomposition_id=0, doe_classifier_cfg={'doe_type': 'mlp', 'load_doe_buffer_path': 'GRF_SUBTASK/doe_epymarl-main/results/buffer/grf', 'load_doe_name': 'load_mlp_classifier.pt', 'load_mode': 'train', 'mlp': {'batch_size': 512, 'hidden_sizes': [128], 'learning_rate': '1e-2', 'test_fraction': 0.1}, 'role_ids': {'task': [0, 1]}, 'save_classifier': True, 'save_doe_name': 'cls_0.pt'}, entropy_coef=0.001, epochs=4, eps_clip=0.2, group_id=0, iter_id=0, layer_id=21, learner='ppo_learner', mask_before_softmax=True, name='mappo', obs_individual_obs=False, q_nstep=5, sample_id=0, save_buffer=True, save_doe_cls=True, standardise_returns=False, standardise_rewards=True, target_update_interval_or_tau=0.01, time_stamp='rag_task_15', use_doe=False, use_rnn=True, seed=560432508, device='cuda')
[INFO 11:58:14] my_main Experiment Parameters:
[INFO 11:58:14] my_main 

{   'action_selector': 'soft_policies',
    'add_value_last_step': True,
    'agent': 'rnn',
    'agent_output_type': 'pi_logits',
    'batch_size': 10,
    'batch_size_run': 10,
    'buffer_cpu_only': True,
    'buffer_size': 10,
    'checkpoint_path': '',
    'common_reward': True,
    'critic_type': 'cv_critic',
    'decomposition_id': 0,
    'doe_classifier_cfg': {   'doe_type': 'mlp',
                              'load_doe_buffer_path': 'GRF_SUBTASK/doe_epymarl-main/results/buffer/grf',
                              'load_doe_name': 'load_mlp_classifier.pt',
                              'load_mode': 'train',
                              'mlp': {   'batch_size': 512,
                                         'hidden_sizes': [   128],
                                         'learning_rate': '1e-2',
                                         'test_fraction': 0.1},
                              'role_ids': {   'task': [   0,
                                                          1]},
                              'save_classifier': True,
                              'save_doe_name': 'cls_0.pt'},
    'entropy_coef': 0.001,
    'env': 'gfootball',
    'env_args': {   'map_name': '5_vs_5',
                    'num_agents': 2,
                    'representation': 'simple115',
                    'rewards': 'scoring, '
                               'reward_21',
                    'seed': 560432508,
                    'time_limit': 150},
    'epochs': 4,
    'eps_clip': 0.2,
    'evaluate': False,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'group_id': 0,
    'hidden_dim': 128,
    'hypergroup': None,
    'iter_id': 0,
    'label': 'default_label',
    'layer_id': 21,
    'learner': 'ppo_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.0003,
    'mac': 'basic_mac',
    'mask_before_softmax': True,
    'name': 'mappo',
    'obs_agent_id': True,
    'obs_individual_obs': False,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'q_nstep': 5,
    'render': False,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'runner': 'parallel',
    'runner_log_interval': 10000,
    'sample_id': 0,
    'save_buffer': True,
    'save_doe_cls': True,
    'save_model': False,
    'save_model_interval': 50000,
    'save_replay': False,
    'seed': 560432508,
    'standardise_returns': False,
    'standardise_rewards': True,
    't_max': 500000,
    'target_update_interval_or_tau': 0.01,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 30,
    'time_stamp': 'rag_task_15',
    'use_cuda': True,
    'use_doe': False,
    'use_rnn': True,
    'use_tensorboard': True,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

[INFO 11:58:14] my_main *******************
[INFO 11:58:14] my_main Tensorboard logging dir:
[INFO 11:58:14] my_main /home/zihao/zihao/PycharmProjects/GRF_SUBTASK-0211/doe_epymarl-main/results/tb_logs/rag_task_15/layer21_decomposition0_subtask0_iter0_sample0
[INFO 11:58:14] my_main *******************
[INFO 11:58:17] my_main Beginning training for 500000 timesteps
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:18] absl Dump "episode_done": count limit reached / disabled
[INFO 11:58:27] my_main t_env: 1500 / 500000
[INFO 11:58:27] my_main Estimated time left: 7 minutes, 10 seconds. Time passed: 9 seconds
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:27] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:33] absl Dump "lost_score": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "lost_score": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:35] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:45] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:54] absl Dump "lost_score": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:58:56] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:07] absl Dump "lost_score": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
[DEBUG 11:59:09] absl Dump "episode_done": count limit reached / disabled
Process Process-9:
Traceback (most recent call last):
  File "/home/zihao/anaconda3/envs/grf2/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/zihao/anaconda3/envs/grf2/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-0211/doe_epymarl-main/src/runners/parallel_runner.py", line 287, in env_worker
    reward, terminated, env_info = env.step(actions)
  File "/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-0211/doe_epymarl-main/src/envs/gfootball/FootballEnv.py", line 91, in step
    obs, rewards, done, infos = self.env.step(actions.tolist())
  File "/home/zihao/anaconda3/envs/grf2/lib/python3.10/site-packages/gym/core.py", line 280, in step
    return self.env.step(action)
  File "/home/zihao/anaconda3/envs/grf2/lib/python3.10/site-packages/gym/core.py", line 314, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-0211/gfootball/rewards/reward_21.py", line 48, in step
    reward, components = self.reward(reward)
  File "/home/zihao/zihao/PycharmProjects/GRF_SUBTASK-0211/gfootball/rewards/reward_21.py", line 40, in reward
    normalized_distance_reward = (ball_travel_distance / self.env.field_length) * self.max_distance_reward
AttributeError: 'FootballEnv' object has no attribute 'field_length'
