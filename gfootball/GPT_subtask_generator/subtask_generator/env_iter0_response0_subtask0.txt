[DEBUG 16:57:59] git.cmd Popen(['git', 'version'], cwd=/home/zihao/PycharmProjects/GRF/football-DoE-0920/gfootball/GPT_subtask_generator/subtask_generator, stdin=None, shell=False, universal_newlines=False)
[DEBUG 16:57:59] git.cmd Popen(['git', 'version'], cwd=/home/zihao/PycharmProjects/GRF/football-DoE-0920/gfootball/GPT_subtask_generator/subtask_generator, stdin=None, shell=False, universal_newlines=False)
[INFO 16:57:59] root Saving to FileStorageObserver in results/sacred.
/home/zihao/anaconda3/envs/grf2/lib/python3.10/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
[DEBUG 16:58:00] pymarl Using capture mode "fd"
[INFO 16:58:00] pymarl Running command 'my_main'
[INFO 16:58:00] pymarl Started run with ID "3"
[DEBUG 16:58:00] pymarl Starting Heartbeat
[DEBUG 16:58:00] my_main Started
[WARNING 16:58:00] my_main CUDA flag use_cuda was switched OFF automatically because no CUDA devices are available!
AAAAAAAAAA namespace(runner='parallel', mac='doe_mac', env='gfootball', common_reward=True, reward_scalarisation='sum', env_args={'map_name': 'scenario_iter0_response0_subtask0', 'num_agents': 3, 'representation': 'simple115', 'rewards': 'scoring, reward_iter0_response0_subtask0', 'time_limit': 150, 'seed': 243333111}, batch_size_run=10, test_nepisode=30, test_interval=10000, test_greedy=True, log_interval=10000, runner_log_interval=10000, learner_log_interval=10000, t_max=20050000, use_cuda=False, buffer_cpu_only=True, use_tensorboard=False, use_wandb=False, wandb_team=None, wandb_project=None, wandb_mode='offline', wandb_save_model=False, save_model=False, save_model_interval=50000, checkpoint_path='', evaluate=False, render=False, load_step=0, save_replay=False, local_results_path='results', gamma=0.99, batch_size=10, buffer_size=10, lr=0.0005, optim_alpha=0.99, optim_eps=1e-05, grad_norm_clip=10, add_value_last_step=True, agent='rnn', hidden_dim=64, obs_agent_id=True, obs_last_action=False, repeat_id=1, label='default_label', hypergroup=None, action_selector='soft_policies', mask_before_softmax=True, target_update_interval_or_tau=0.01, obs_individual_obs=False, agent_output_type='pi_logits', learner='doe_ia2c_learner', entropy_coef=0.01, standardise_returns=False, standardise_rewards=True, use_rnn=True, q_nstep=5, critic_type='ac_critic', name='doe_ia2c', use_doe=True, doe_type='mlp', ent_coef=1.0, base_lr=1.0, base_ent=1.0, boost_lr_coef=1.0, boost_ent_coef=1.0, doe_classifier_cfg={'doe_type': 'mlp', 'load_mode': 'train', 'save_classifier': True, 'save_pathname': 'mlp_classifier.pt', 'path_to_classifier': 'mlp_classifier.pt', 'mlp': {'hidden_sizes': [128], 'batch_size': 512, 'test_fraction': 0.1, 'learning_rate': '1e-2'}, 'role_ids': {'defence': [0, 1], 'attack': [2, 3]}}, seed=243333111, device='cpu')
[INFO 16:58:00] my_main Experiment Parameters:
[INFO 16:58:00] my_main 

{   'action_selector': 'soft_policies',
    'add_value_last_step': True,
    'agent': 'rnn',
    'agent_output_type': 'pi_logits',
    'base_ent': 1.0,
    'base_lr': 1.0,
    'batch_size': 10,
    'batch_size_run': 10,
    'boost_ent_coef': 1.0,
    'boost_lr_coef': 1.0,
    'buffer_cpu_only': True,
    'buffer_size': 10,
    'checkpoint_path': '',
    'common_reward': True,
    'critic_type': 'ac_critic',
    'doe_classifier_cfg': {   'doe_type': 'mlp',
                              'load_mode': 'train',
                              'mlp': {   'batch_size': 512,
                                         'hidden_sizes': [   128],
                                         'learning_rate': '1e-2',
                                         'test_fraction': 0.1},
                              'path_to_classifier': 'mlp_classifier.pt',
                              'role_ids': {   'attack': [   2,
                                                            3],
                                              'defence': [   0,
                                                             1]},
                              'save_classifier': True,
                              'save_pathname': 'mlp_classifier.pt'},
    'doe_type': 'mlp',
    'ent_coef': 1.0,
    'entropy_coef': 0.01,
    'env': 'gfootball',
    'env_args': {   'map_name': 'scenario_iter0_response0_subtask0',
                    'num_agents': 3,
                    'representation': 'simple115',
                    'rewards': 'scoring, '
                               'reward_iter0_response0_subtask0',
                    'seed': 243333111,
                    'time_limit': 150},
    'evaluate': False,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'hidden_dim': 64,
    'hypergroup': None,
    'label': 'default_label',
    'learner': 'doe_ia2c_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.0005,
    'mac': 'doe_mac',
    'mask_before_softmax': True,
    'name': 'doe_ia2c',
    'obs_agent_id': True,
    'obs_individual_obs': False,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'q_nstep': 5,
    'render': False,
    'repeat_id': 1,
    'reward_scalarisation': 'sum',
    'runner': 'parallel',
    'runner_log_interval': 10000,
    'save_model': False,
    'save_model_interval': 50000,
    'save_replay': False,
    'seed': 243333111,
    'standardise_returns': False,
    'standardise_rewards': True,
    't_max': 20050000,
    'target_update_interval_or_tau': 0.01,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 30,
    'use_cuda': False,
    'use_doe': True,
    'use_rnn': True,
    'use_tensorboard': False,
    'use_wandb': False,
    'wandb_mode': 'offline',
    'wandb_project': None,
    'wandb_save_model': False,
    'wandb_team': None}

/home/zihao/anaconda3/envs/grf2/lib/python3.10/site-packages/sacred/stdout_capturing.py:179: UserWarning: tee_stdout.wait timeout. Forcibly terminating.
  warnings.warn("tee_stdout.wait timeout. Forcibly terminating.")
/home/zihao/anaconda3/envs/grf2/lib/python3.10/site-packages/sacred/stdout_capturing.py:185: UserWarning: tee_stderr.wait timeout. Forcibly terminating.
  warnings.warn("tee_stderr.wait timeout. Forcibly terminating.")
[DEBUG 16:58:02] pymarl Stopping Heartbeat
[ERROR 16:58:02] pymarl Failed after 0:00:03!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/home/zihao/PycharmProjects/GRF/football-DoE-0920/doe_epymarl-main/src/main.py", line 38, in my_main
    run(_run, config, _log)
  File "/home/zihao/PycharmProjects/GRF/football-DoE-0920/doe_epymarl-main/src/run.py", line 70, in run
    run_sequential(args=args, logger=logger)
  File "/home/zihao/PycharmProjects/GRF/football-DoE-0920/doe_epymarl-main/src/run.py", line 155, in run_sequential
    doe_classifier = doe_classifier_config_loader(
  File "/home/zihao/PycharmProjects/GRF/football-DoE-0920/doe_epymarl-main/src/modules/doe/__init__.py", line 18, in doe_classifier_config_loader
    return cls.from_config(n_agents, cfg, buffer_path)
  File "/home/zihao/PycharmProjects/GRF/football-DoE-0920/doe_epymarl-main/src/modules/doe/mlp_class.py", line 130, in from_config
    classifier = cls.from_config_train(n_agents, cfg, buffer_path)
  File "/home/zihao/PycharmProjects/GRF/football-DoE-0920/doe_epymarl-main/src/modules/doe/mlp_class.py", line 148, in from_config_train
    role_list[agent_id] = label
IndexError: list assignment index out of range

